# Core dependencies from Dockerfile and setup.cfg
# Note: torch is installed from PyTorch CUDA wheel in Dockerfile
# For local development, install torch based on your CUDA version:
# CUDA 11.8: pip install torch==2.6.0+cu118 --index-url https://download.pytorch.org/whl/cu118
# CPU only: pip install torch==2.6.0

torch>=2.6
# bitsandbytes 0.41.3 requires triton.ops which was removed in newer Triton.
# Pin triton to 2.x in Dockerfile for GPU builds, or use newer bitsandbytes if available.
bitsandbytes>=0.41.3
transformers>=4.55.0,<4.56.0
# accelerate: Updated for torch 2.6 compatibility
accelerate>=0.30.0
huggingface-hub>=0.20.0,<1.0.0
tokenizers>=0.15.0
pillow>=10.0.0
speedtest-cli==2.1.3
hivemind @ git+https://github.com/learning-at-home/hivemind.git@213bff98a62accb91f254e2afdccbf1d69ebdea9
tensor_parallel==1.0.23
humanfriendly
async-timeout>=4.0.2
cpufeature>=0.2.0; platform_machine == "x86_64"
packaging>=20.9
sentencepiece>=0.1.99
# peft: Updated for newer transformers compatibility
peft>=0.10.0
safetensors>=0.4.0
Dijkstar>=2.6.0
numpy<2

