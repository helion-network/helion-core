# Volumes:
# - petals-cache: shared model cache (/cache) to avoid re-downloading weights
volumes:
  petals-cache:

networks:
  petals-net:
    name: petals-net

services:
  # -------------------- GPU WORKER --------------------
  worker:
    build:
      context: ../..
      dockerfile: Dockerfile
    container_name: petals-worker
    # Windows Compose requires a LIST for GPUs; 'ipc: host' is not supported on Windows
    gpus:
      - count: all
    env_file:
      - ./.env
    environment:
      MODEL_ID: ${MODEL_ID}
      WORKER_PUBLIC_IP: ${WORKER_PUBLIC_IP}
      INITIAL_PEERS: ${INITIAL_PEERS}
      HUGGINGFACE_HUB_TOKEN: ${HUGGINGFACE_HUB_TOKEN}
      PORT: ${PORT}
      BALANCE_QUALITY: ${BALANCE_QUALITY}
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    command: >
      bash -lc "
      python -m petals.cli.run_server -c /home/petals/config.yml
      "
    ports:
      - "${PORT:-31330}:${PORT:-31330}"
    volumes:
      - petals-cache:/cache
      - ./config.yml:/home/petals/config.yml:ro
    # networks: [petals-net]
    # restart: unless-stopped